# Implementation of Natural Language Processing approaches (statistical, n-grams, token-based) to vulnerability detection

Based on works by Russel et al. among other common NLP-based approaches (https://arxiv.org/abs/1807.04320).

## Prerequisites

- Linux environment
- Nvidia GPU using Cuda 11.6 or later (2x Tesla V100 used for testing)
- 256 GB memory (768GB used for testing)
- Install requirements (pip install -r requirements.txt)
- Open preprocessor.py and change Clang path (default: CURRENTDIR/clang/bin/clang).
- Download VDISC dataset(https://osf.io/d45bw/) and extract to current directory.
- Optional: Download Juliet dataset(https://samate.nist.gov/SARD/test-suites/112) for exploration and processing using juliet.ipynb.

## Running Jupyter

Use own configuration or change start.sh to your preferences (requires tmux).

## Reproducing results

main.ipynb can produce different combinations of models using statistical features, n-grams and token-based approaches.

### CNN-1

This approach uses text-classification for CNN to classify vulnerable code using a tokenized representation of the data with 268 hand-picked tokens
Set the following to True:

- h5_processing = True
- clang_processing = True
- lex_processing = True

Set the save path for the model, and run the CNN training and validation.

### CNN-2

This approach uses text-classification for CNN to classify vulnerable code using a tokenized representation of the data with 4000~ most common tokens.
Set the following to True:

- h5_processing = True
- lex_processing_raw = True
- train_raw_features = True

Set the save path for the model, and re-run the CNN training and validation
Note: Remember to change the save path in order to not overwrite CNN-1.

### Random Forest + CNN1/2

The third approach uses Deep Representation Learning to extract 512 features from each of the previous CNNs. These 1024 features are then trained on by a RF model. Run the remainder of the main.ipynb file to produce this result. Note that the location and parameters of the previous models must be manually changed to fit your models.

### Random Forest + Trivial features / n-grams

The last approaches using trivial features and n-grams do not perform as well as RF + CNN1/2, however, they can be explored by changing the creation of the "neural_features" array.

## Best results

The best results were achieved using RF + CNN1 + CNN2. Results using 2500 estimators for RF:

### Multi-label

AUC ROC total: 0.942 \
AUC ROC weighted: 0.942 \
AUC PR: 0.468 \
AUC PR weighted: 0.520 \
MCC: 0.523 \
F1: 0.524 \
ACC: 98.024

### Binary

AUC ROC: 0.921 \
AUC PR: 0.568 \
MCC: 0.567 \
F1: 0.591 \
ACC: 93.684
